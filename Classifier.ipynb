{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from math import floor\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Dense, Dropout, Flatten, MaxPooling2D, Input, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import History \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import backend as K\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './seg_train/seg_train/'\n",
    "test_path = './seg_test/seg_test/'\n",
    "Labels = ['buildings', 'forest','glacier','mountain','sea','street']\n",
    "label_dict = {0:'buildings', 1:'forest', 2:'glacier', 3:'mountain', 4:'sea', 5:'street'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = len(os.listdir(train_path+'buildings'))*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    #train_label_count = {'buildings':0, 'forest':0, 'glacier':0, 'mountain':0, 'sea':0, 'street':0}\n",
    "    images = list()\n",
    "    lbls = list()\n",
    "    for label in Labels:\n",
    "        count = 0\n",
    "        for image in os.listdir(path+label):\n",
    "            if count < min_count:\n",
    "                img = cv2.imread(path+label+r'/'+image)\n",
    "                img = Image.fromarray(img , 'RGB')\n",
    "                img = img.resize((50,50))\n",
    "                images.append(np.array(img)/255)\n",
    "                if label == 'buildings':\n",
    "                    lbl = 0\n",
    "                elif label == 'forest':\n",
    "                    lbl = 1\n",
    "                elif label == 'glacier':\n",
    "                    lbl = 2\n",
    "                elif label == 'mountain':\n",
    "                    lbl = 3\n",
    "                elif label == 'sea':\n",
    "                    lbl = 4\n",
    "                else:\n",
    "                    lbl = 5\n",
    "                lbls.append(lbl)\n",
    "                if path == train_path:\n",
    "                    rotated = img.rotate(45)\n",
    "                    flipped = np.fliplr(img)\n",
    "                    images.append(np.array(rotated)/255)\n",
    "                    images.append(np.array(flipped)/255)\n",
    "                    lbls.append(lbl)\n",
    "                    lbls.append(lbl)\n",
    "                    #train_label_count[label] += 3\n",
    "                    count += 3\n",
    "                \n",
    "    images = np.array(images)\n",
    "    lbls = np.array(lbls)\n",
    "    \n",
    "    return shuffle(images, lbls, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = get_data(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = get_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples_len = floor(len(train_images)/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A, train_B = train_images, train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_B (InputLayer)            [(None, 50, 50, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 50, 50, 32)   416         input_B[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 25, 25, 32)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 32)   4128        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 12, 12, 32)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 12, 12, 32)   0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 4608)         0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_A (InputLayer)            [(None, 50, 50, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 500)          2304500     flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 7500)         0           input_A[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 500)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8000)         0           flatten_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 6)            48006       concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,357,050\n",
      "Trainable params: 2,357,050\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_A = Input(shape=train_A.shape[1:], name='input_A')\n",
    "flat_A = Flatten()(input_A)\n",
    "input_B = Input(shape=train_B.shape[1:], name='input_B')\n",
    "conv_1 = Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\")(input_B)\n",
    "pool_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)\n",
    "conv_2 = Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\")(pool_1)\n",
    "pool_2 = MaxPooling2D(pool_size=(2, 2))(conv_2)\n",
    "drop_1 = Dropout(0.2)(pool_2)\n",
    "flat_2 = Flatten()(drop_1)\n",
    "hidden1 = Dense(500, activation='relu')(flat_2)\n",
    "drop_2 = Dropout(0.2)(hidden1)\n",
    "concat = Concatenate()([flat_A, drop_2])\n",
    "output = Dense(6, activation=\"softmax\")(concat)\n",
    "model = Model(inputs=[input_A, input_B], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27606 samples, validate on 11832 samples\n",
      "Epoch 1/50\n",
      "27606/27606 [==============================] - 41s 1ms/sample - loss: 1.2241 - accuracy: 0.5507 - val_loss: 0.8911 - val_accuracy: 0.6611\n",
      "Epoch 2/50\n",
      "27606/27606 [==============================] - 41s 2ms/sample - loss: 0.9554 - accuracy: 0.6603 - val_loss: 0.8114 - val_accuracy: 0.7093\n",
      "Epoch 3/50\n",
      "27606/27606 [==============================] - 41s 1ms/sample - loss: 0.8859 - accuracy: 0.6984 - val_loss: 0.7958 - val_accuracy: 0.7170\n",
      "Epoch 4/50\n",
      "27606/27606 [==============================] - 41s 1ms/sample - loss: 0.7599 - accuracy: 0.7347 - val_loss: 0.7820 - val_accuracy: 0.7221\n",
      "Epoch 5/50\n",
      "27606/27606 [==============================] - 40s 1ms/sample - loss: 0.7058 - accuracy: 0.7567 - val_loss: 0.7431 - val_accuracy: 0.7546\n",
      "Epoch 6/50\n",
      "27606/27606 [==============================] - 41s 1ms/sample - loss: 0.6275 - accuracy: 0.7825 - val_loss: 0.7663 - val_accuracy: 0.7675\n",
      "Epoch 7/50\n",
      "27606/27606 [==============================] - 39s 1ms/sample - loss: 0.5638 - accuracy: 0.8045 - val_loss: 0.7516 - val_accuracy: 0.7585\n",
      "Epoch 8/50\n",
      "27606/27606 [==============================] - 41s 1ms/sample - loss: 0.5147 - accuracy: 0.8220 - val_loss: 0.8422 - val_accuracy: 0.7456\n",
      "Epoch 9/50\n",
      "27606/27606 [==============================] - 41s 1ms/sample - loss: 0.4711 - accuracy: 0.8376 - val_loss: 0.9240 - val_accuracy: 0.7308\n",
      "Epoch 10/50\n",
      "27584/27606 [============================>.] - ETA: 0s - loss: 0.4378 - accuracy: 0.8501Restoring model weights from the end of the best epoch.\n",
      "27606/27606 [==============================] - 40s 1ms/sample - loss: 0.4376 - accuracy: 0.8501 - val_loss: 0.7971 - val_accuracy: 0.7748\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5735b6d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_A, train_B], train_labels, epochs=50,validation_split=.3, callbacks=[monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ensemble():\n",
    "    models = list()\n",
    "    for i in range(1,7):\n",
    "        model=Sequential()\n",
    "        model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=train_images.shape[1:]))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(250*i,activation=\"relu\"))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(6,activation=\"softmax\"))\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(train_images, train_labels):\n",
    "    #new_train_images, new_train_labels = train_images, train_labels\n",
    "    trained_models = list()\n",
    "    models = build_ensemble()\n",
    "    for model in models:\n",
    "        #model_train_images = new_train_images[:samples_len]\n",
    "        #model_train_labels = new_train_labels[:samples_len]\n",
    "        model.fit(train_images,train_labels,epochs=50,validation_split=.3, callbacks=[monitor])\n",
    "        trained_models.append(model)\n",
    "        #new_train_images = new_train_images[samples_len:]\n",
    "        #new_train_labels = new_train_labels[samples_len:]\n",
    "        \n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#trained_ensemble = train_ensemble(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for model in trained_ensemble:\n",
    "#    model.evaluate(test_images,test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 1s 395us/sample - loss: 0.7632 - accuracy: 0.7470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7632287295659383, 0.747]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([test_images,test_images],test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda131495974d4643718c5873ac07c16029"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
