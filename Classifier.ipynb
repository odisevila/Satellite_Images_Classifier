{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import History \n",
    "from tensorflow.keras import backend as K\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './seg_train/seg_train/'\n",
    "test_path = './seg_test/seg_test/'\n",
    "Labels = ['buildings', 'forest','glacier','mountain','sea','street']\n",
    "label_dict = {0:'buildings', 1:'forest', 2:'glacier', 3:'mountain', 4:'sea', 5:'street'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    train_label_count = {'buildings':0, 'forest':0, 'glacier':0, 'mountain':0, 'sea':0, 'street':0}\n",
    "    images = list()\n",
    "    lbls = list()\n",
    "    for label in Labels:\n",
    "        count = 0\n",
    "        for image in os.listdir(path+label):\n",
    "            if count < 4382:\n",
    "                img = cv2.imread(path+label+r'/'+image)\n",
    "                img = Image.fromarray(img , 'RGB')\n",
    "                img = img.resize((50,50))\n",
    "                images.append(np.array(img)/255)\n",
    "                if label == 'buildings':\n",
    "                    lbl = 0\n",
    "                elif label == 'forest':\n",
    "                    lbl = 1\n",
    "                elif label == 'glacier':\n",
    "                    lbl = 2\n",
    "                elif label == 'mountain':\n",
    "                    lbl = 3\n",
    "                elif label == 'sea':\n",
    "                    lbl = 4\n",
    "                else:\n",
    "                    lbl = 5\n",
    "                lbls.append(lbl)\n",
    "                if path == train_path:\n",
    "                    rotated = img.rotate(45)\n",
    "                    images.append(np.array(rotated)/255)\n",
    "                    lbls.append(lbl)\n",
    "                    train_label_count[label] += 2\n",
    "                    count += 2\n",
    "                \n",
    "    print(train_label_count)   \n",
    "    images = np.array(images)\n",
    "    lbls = np.array(lbls)\n",
    "    \n",
    "    return shuffle(images, lbls, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'buildings': 4382, 'forest': 4382, 'glacier': 4382, 'mountain': 4382, 'sea': 4382, 'street': 4382}\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = get_data(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'buildings': 0, 'forest': 0, 'glacier': 0, 'mountain': 0, 'sea': 0, 'street': 0}\n"
     ]
    }
   ],
   "source": [
    "test_images, test_labels = get_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 50, 50, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               1152500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3006      \n",
      "=================================================================\n",
      "Total params: 1,166,050\n",
      "Trainable params: 1,166,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=train_images.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6,activation=\"softmax\"))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19719 samples, validate on 6573 samples\n",
      "Epoch 1/50\n",
      "19719/19719 [==============================] - 19s 984us/sample - loss: 1.0383 - accuracy: 0.5968 - val_loss: 0.8300 - val_accuracy: 0.6924\n",
      "Epoch 2/50\n",
      "19719/19719 [==============================] - 20s 993us/sample - loss: 0.8088 - accuracy: 0.6998 - val_loss: 0.8353 - val_accuracy: 0.6829\n",
      "Epoch 3/50\n",
      "19719/19719 [==============================] - 21s 1ms/sample - loss: 0.7078 - accuracy: 0.7404 - val_loss: 0.6984 - val_accuracy: 0.7412\n",
      "Epoch 4/50\n",
      "19719/19719 [==============================] - 21s 1ms/sample - loss: 0.6388 - accuracy: 0.7630 - val_loss: 0.7331 - val_accuracy: 0.7275\n",
      "Epoch 5/50\n",
      "19719/19719 [==============================] - 20s 1ms/sample - loss: 0.5874 - accuracy: 0.7840 - val_loss: 0.6202 - val_accuracy: 0.7729\n",
      "Epoch 6/50\n",
      "19719/19719 [==============================] - 20s 1ms/sample - loss: 0.5444 - accuracy: 0.7996 - val_loss: 0.6134 - val_accuracy: 0.7742\n",
      "Epoch 7/50\n",
      "19719/19719 [==============================] - 20s 1ms/sample - loss: 0.4816 - accuracy: 0.8267 - val_loss: 0.6155 - val_accuracy: 0.7803\n",
      "Epoch 8/50\n",
      "19719/19719 [==============================] - 20s 1ms/sample - loss: 0.4388 - accuracy: 0.8380 - val_loss: 0.5996 - val_accuracy: 0.7920\n",
      "Epoch 9/50\n",
      "19719/19719 [==============================] - 20s 1ms/sample - loss: 0.3934 - accuracy: 0.8573 - val_loss: 0.6070 - val_accuracy: 0.7943\n",
      "Epoch 10/50\n",
      "19719/19719 [==============================] - 20s 1ms/sample - loss: 0.3524 - accuracy: 0.8741 - val_loss: 0.6384 - val_accuracy: 0.7756\n",
      "Epoch 11/50\n",
      "19719/19719 [==============================] - 20s 1ms/sample - loss: 0.3064 - accuracy: 0.8865 - val_loss: 0.6320 - val_accuracy: 0.7914\n",
      "Epoch 12/50\n",
      "19719/19719 [==============================] - 21s 1ms/sample - loss: 0.2684 - accuracy: 0.9012 - val_loss: 0.6419 - val_accuracy: 0.7907\n",
      "Epoch 13/50\n",
      "19680/19719 [============================>.] - ETA: 0s - loss: 0.2420 - accuracy: 0.9126Restoring model weights from the end of the best epoch.\n",
      "19719/19719 [==============================] - 21s 1ms/sample - loss: 0.2422 - accuracy: 0.9125 - val_loss: 0.6552 - val_accuracy: 0.8022\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_h = model.fit(train_images,train_labels,epochs=50,validation_split=.25, callbacks=[monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 1s 264us/sample - loss: 0.5939 - accuracy: 0.7910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.59386483502388, 0.791]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda131495974d4643718c5873ac07c16029"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
